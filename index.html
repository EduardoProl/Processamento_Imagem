<!DOCTYPE html>
<html lang="pt-PT">

<!-- Incluir CSS e JS do CodeMirror -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.64.0/codemirror.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.64.0/theme/dracula.min.css"> <!-- Tema escuro -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.64.0/codemirror.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.64.0/mode/python/python.min.js"></script> <!-- Para destacar Python -->

<head>
    <link rel="icon" href="./images/PI_LOGO.png">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>P.I. LEIC</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <button id="menuButton">
            <img src="https://img.icons8.com/?size=100&id=eofQ1g5BaAx6&format=png&color=000000" alt="Menu Icon" />
        </button>
        <h1>Processamento de Imagem - LEIC 2024/2025<h1>
    </header>

    <!-- Side Navigation -->
    <div id="sideNav">
        <text class='index_title'>Introdução Teórica:</text>
        <a href="#EspacosCor">Espaços de Cor</a>
        <a href="#OperacoesMorfologicas">Operações Morfológicas</a>
        <a href="#Filtragem">Filtros</a>
        <a href="#Outros">Outros</a>
        <br>

        <text class='index_title'>Básico:</text>    
          
        <a href="#Abrir_imagens">Abrir Imagens</a>
        <a href="#Imagem_binaria">Imagem Binária</a>
        <a href="#Imagem_grayscale">Imagem em Escala de Cinza</a>
        <br>
        <text class='index_title'>Centroides e Momentos da imagem:</text>
          
        <a href="#codeSection">Centroides</a>
        <a href="#codeSection1">Momentos Centrados</a>
        <a href="#codeSection2">Orientação</a>
        <a href="#codeSection3">Desenhar linha com base no angulo</a>
        <a href="#codeSection4">Excentricidade</a>
        <br>
        <text class='index_title'>Filtragem:</text>
          
        <a href="#Dil_ero">Dilate e Erode</a>
        <a href="#Eliminar_Ruido">Eliminar Ruido com dilate e erode</a>
        <a href="#Brilho_GAMA">Brilho, contraste e Gama</a>
        <a href="#BLUR_INT">Blur integral</a>
        <a href="#BLUR_GAUSS">Blur gaussiano</a>
        <a href="#Sobel">Filtro de Sobel</a>

        <br>
        <text class='index_title'>Tarefas:</text>
          
        <a href="#Radon">Transformada de Radon</a>
        <a href="#Integral">Matriz integral comulativa</a>
        <a href="#Filtros">Filtros</a>
        <a href="#Arucos">Arucos</a>
        <a href="#Calibrar_Camera">Calibrar Camera</a>

        <br>
        <text class='index_title'>Exercício para Teste</text>
        <a href="#Exercicio1">Exercício 1 - GrayScale</a>
        <a href="#Exercicio2">Exercício 2 - Segmentação por cor</a>
        <a href="#Exercicio3">Exercício 3 - Segmentação por cor (HSV)</a>
        <a href="#Exercicio4">Exercício 4 - Blobs/Contornos e Excentricidade</a>
        <a href="#Exercicio5">Exercício 5 - Leitura de Arucos</a>
        <a href="#Exercicio6_1">Exercicio 6.1 - Correção de perspectiva "à mão"</a>
        <a href="#Exercicio6_2">Exercicio 6.2 - Correção de perspectiva automática</a>
        <a href="#Exercicio6_3">Exercicio 6.3 - Correção de perspectiva automática com aspect-ratio automático</a>
        
        <br>
        <br>
        <br>
    </div>

    <main>
        <text class="titulo">Introdução Teórica</text>
        <section id="teoria">
            
            <article>
                <a></a>
                <h2 id="EspacosCor">1. Espaços de Cor</h2>
                <p>
                    Os <strong>espaços de cor</strong> são representações matemáticas que permitem descrever cores em imagens digitais. Cada espaço organiza as cores de forma diferente, dependendo da aplicação ou do sistema de captura e exibição.
                </p>
                <image src="./images/hsvVSrgb.jpg" alt="HSV vs RGB" width="100%"></image>
                <h3>Principais Espaços de Cor:</h3>
                <ul>
                    <li><strong>RGB (Red, Green, Blue):</strong> Modelo aditivo baseado em três componentes (vermelho, verde e azul). Amplamente usado em dispositivos digitais.</li>
                    <li><strong>HSV (Hue, Saturation, Value):</strong> Modelo baseado na percepção humana de cor, separando tonalidade (cor), saturação (intensidade) e valor (brilho).</li>
                    <li><strong>CMYK (Cyan, Magenta, Yellow, Black):</strong> Modelo subtrativo, usado em impressão.</li>
                    <li><strong>YUV/YCrCb:</strong> Representa luminância (Y) e crominância (U e V ou Cr e Cb). É utilizado em compressão de vídeo e transmissão de sinais.</li>
                    <li><strong>Lab:</strong> Modelo perceptualmente uniforme que separa a luz (L) dos componentes de cor (a e b).</li>
                </ul>
                <h3>Aplicações:</h3>
                <ul>
                    <li>Conversão entre espaços de cor (ex.: RGB para HSV) é útil em segmentação, ajuste de brilho/contraste e processamento orientado a cor.</li>
                    <li>Melhorar a segmentação de objetos ao trabalhar com características como tonalidade (HSV) ou luminância (YUV).</li>
                </ul>
            </article>
    
            <article>
                <h2 id="OperacoesMorfologicas">2. Operações Morfológicas</h2>
                <p>
                    As operações morfológicas são técnicas baseadas na teoria de conjuntos para processar imagens binárias ou escala de cinza, focadas na forma e estrutura dos objetos.
                </p>
                <image src="./images/erodeVSdilate.jpg" alt="Erode vs Dilate" width="100%"></image>
                <h3>Operações Básicas:</h3>
                <ul>
                    <li><strong>Erosão:</strong> Remove pixels na borda de objetos, reduzindo o tamanho de regiões. É útil para eliminar ruído.</li>
                    <li><strong>Dilatação:</strong> Adiciona pixels às bordas de objetos, expandindo regiões. Ajuda a preencher lacunas.</li>
                    <li><strong>Abertura:</strong> Erosão seguida de dilatação. Remove pequenos objetos ou ruídos enquanto preserva a forma geral.</li>
                    <li><strong>Fechamento:</strong> Dilatação seguida de erosão. Preenche lacunas pequenas e suaviza as bordas de objetos.</li>
                    <li><strong>Gradiente Morfológico:</strong> Diferença entre a dilatação e a erosão. Realça as bordas dos objetos.</li>
                </ul>
                <h3>Aplicações:</h3>
                <ul>
                    <li>Segmentação de objetos.</li>
                    <li>Remoção de ruído (ex.: "salt and pepper").</li>
                    <li>Extração de bordas.</li>
                </ul>
            </article>
    
            <article>
                <h2 id="Filtragem">3. Filtros</h2>
                <p>
                    Filtros são operações aplicadas a imagens para modificar ou extrair informações, como suavização, realce de bordas ou remoção de ruído.
                </p>
                <h3>Tipos de Filtros:</h3>
                <ul>
                    <li>
                        <strong>Filtros Espaciais:</strong>
                        <br>
                        <image src="./images/gaussian.png" alt="Filtro Gaussiano" width="100%"></image>
                        <ul>
                            <li><strong>Filtro Média:</strong> Suaviza a imagem ao calcular a média dos valores dos pixels em uma janela. Reduz ruído, mas pode borrar detalhes.</li>
                            <li><strong>Filtro Mediana:</strong> Substitui o valor do pixel pelo valor mediano na vizinhança. É eficaz contra ruídos impulsivos.</li>
                            <li><strong>Filtro Gaussiano:</strong> Aplica uma função gaussiana para suavizar a imagem, preservando transições suaves.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Filtros para Detecção de Bordas:</strong>
                        <br>
                        <image src="./images/sobel.png" alt="Filtro de Sobel" width="100%" style="background-color: white;"></image>
                        <ul>
                            <li><strong>Sobel:</strong> Detecta bordas calculando gradientes em direções horizontais e verticais.</li>
                            <li><strong>Laplaciano:</strong> Detecta bordas ao realçar regiões onde há mudanças rápidas de intensidade.</li>
                            <li><strong>Canny:</strong> Técnica robusta que combina suavização, gradiente e limiares para detectar bordas com alta precisão.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Filtros no Domínio da Frequência:</strong>
                        <ul>
                            <li>Usam transformadas como a <strong>Transformada de Fourier</strong> para aplicar filtros passa-baixa (suavização) ou passa-alta (realce de bordas) diretamente no espectro de frequências.</li>
                        </ul>
                    </li>
                </ul>
                <h3>Aplicações:</h3>
                <ul>
                    <li>Redução de ruído em pré-processamento.</li>
                    <li>Realce de características específicas, como bordas ou texturas.</li>
                    <li>Segmentação e detecção de padrões.</li>
                </ul>
            </article>
    
            <article>
                <h2 id="Outros">4. Outros Tópicos Relevantes</h2>
                <h3>Transformações Geométricas:</h3>
                <p>Incluem operações como translação, rotação, escalonamento e deformação. Usadas para alinhar ou ajustar imagens, como na criação de mosaicos e panoramas.</p>
                <h3>Segmentação:</h3>
                <p>Separação de uma imagem em regiões ou objetos. Métodos comuns incluem segmentação baseada em limiar (thresholding), segmentação por bordas e segmentação por agrupamento (clustering), como o algoritmo K-means.</p>
                <h3>Equalização de Histograma:</h3>
                <p>Técnica para melhorar o contraste ajustando a distribuição dos níveis de intensidade da imagem. Usada em imagens de baixa iluminação ou com contraste desigual.</p>
                <h3>Detecção de Padrões e Objetos:</h3>
                <p>Métodos baseados em características (ex.: contornos, texturas) ou aprendizado de máquina (redes neurais convolucionais, YOLO, etc.).</p>
                <h3>Transformada de Hough:</h3>
                <p>Utilizada para detecção de formas geométricas, como linhas e círculos, em imagens.</p>
                <h3>Compressão:</h3>
                <p>Métodos como JPEG e PNG para reduzir o tamanho de arquivos de imagem sem perder qualidade significativa (compressão com perdas ou sem perdas).</p>
            </article>
        </section>
      
         
        <text class="titulo">Básico:</text>
         
        <section id="Abrir_imagens">
            <h2>Abrir Imagens</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox3" class="codeBox">
img = plt.imread("../imagens/imagem_a.jpg")
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>
        <section id="Imagem_binaria">
            <h2>Converter para binário</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox3" class="codeBox">
def to_binary(image_gray, threshold=0.5):
    """
    Converte uma imagem em escala de cinza para binário.

    Parâmetros:
    - image_gray (numpy array): Imagem em escala de cinza.
    - threshold (float): Valor de limiar para conversão (0 a 1).

    Retorna:
    - numpy array: Imagem binária.
    """
    return (image_gray > threshold).astype(np.uint8)
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>
        <section id="Imagem_grayscale">
            <h2>Converter para preto e branco</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox3" class="codeBox">
def to_grayscale(image):
    """
    Converte uma imagem RGB para escala de cinza.

    Parâmetros:
    - image (numpy array): Imagem RGB.

    Retorna:
    - numpy array: Imagem em escala de cinza.
    """
    return np.mean(image, axis=2)
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

         
        <text class="titulo">Momentos da Imagem:</text>
         
        <section id="codeSection">
            <h2>Centroides</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox1" class="codeBox">def centroide(imagem_hex):
M00 = M01 = M10 = 0

for i in range(imagem_hex.shape[0]):
    for j in range(imagem_hex.shape[1]):
        M00 += imagem_hex[i, j]
        M01 += (imagem_hex[i, j] * j)
        M10 += (imagem_hex[i, j] * i)
return M01 / M00, M10 / M00
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="codeSection1">
            <h2>Momentos Centrados</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox2" class="codeBox">def momentos_centrados(img):
"""Calcula os momentos centrais de segunda ordem mu11, mu02, mu20."""
y, x = centroide(img)
mu11 = mu02 = mu20 = 0
for i in range(img.shape[0]):
    for j in range(img.shape[1]):
        mu11 += (i - x) * (j - y) * img[i, j]
        mu02 += (i - y) ** 2 * img[i, j]
        mu20 += (j - x) ** 2 * img[i, j]
return mu11, mu02, mu20
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="codeSection2">
            <h2>Orientação</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox3" class="codeBox">def calcular_orientacao(img):
    mu11, mu02, mu20 = momentos_centrados(img)
    # Calcular a orientação (em radianos)
    theta = 0.5 * np.arctan2(2 * mu11, (mu20 - mu02))
    return np.degrees(theta) # Retorna a orientação em graus
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="codeSection3">
            <h2>Desenhar linha com base no angulo</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox4" class="codeBox">def desenhar_linha(x, y, theta, comprimento=150, cor='red'):
    # Convertendo ângulo para radianos
    theta_rad = np.radians(theta)
    
   # Calculando os componentes de deslocamento da seta (dx, dy)
    dx = comprimento * np.cos(theta_rad)
    dy = -comprimento * np.sin(theta_rad)  
    # Desenhando a seta com plt.arrow
    plt.arrow(x, y, dx, dy, head_width=15, head_length=10, fc=cor, ec=cor)
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="codeSection4">
            <h2>Excentricidade</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">def calcular_excentricidade(img):
    """Calcula a excentricidade da figura com base nos momentos centrais."""
    mu11, mu02, mu20 = momentos_centrados(img)
    
    # Matriz de covariância dos momentos centrais
    cov_matrix = np.array([[mu20, mu11],
                           [mu11, mu02]])
    
    # Calculando os autovalores da matriz de covariância
    eigenvalues, _ = np.linalg.eig(cov_matrix)
    
    # Ordenando os autovalores para garantir que lambda1 >= lambda2
    lambda1, lambda2 = sorted(eigenvalues, reverse=True)
    
    # Excentricidade
    excentricidade = np.sqrt(1 - (lambda2 / lambda1))
    return excentricidade
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>
         
        <text class="titulo">Filtragem:</text>
         
        <section id="Dil_ero">
            <h2>Dilate e Erode</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">
I_dilate = sc.binary_dilation(Img,structure = np.ones((5,5)))
I_eroded = sc.binary_erosion(Img,structure = np.ones((9,9)))
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="Eliminar_Ruido">
            <h2>Eliminar Ruido</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">
I_dilate = sc.binary_dilation(Iseg,structure = np.ones((5,5)))
I_eroded = sc.binary_erosion(I_dilate,structure = np.ones((9,9)))
I_final = sc.binary_dilation(I_eroded,structure = np.ones((5,5)))
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="Brilho_GAMA">
            <h2>Brilho, Contraste e Gama</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">
import matplotlib.pyplot as plt
import numpy as np

# Brilho
imagem = plt.imread("car.jpg")
imagem = imagem.astype(np.float32)
brilho = 30
imagem_brilho = imagem + brilho
imagem_brilho = np.clip(imagem_brilho, 0, 255)
imagem_brilho = imagem_brilho.astype(np.uint8)

#Contraste
imagem = plt.imread("car.jpg")
imagem = imagem.astype(np.float32)
alpha = 1.5
imagem_contraste = imagem * alpha
imagem_contraste = np.clip(imagem_contraste, 0, 255)
imagem_contraste = imagem_contraste.astype(np.uint8)
                    
#Gama
imagem = plt.imread("car.jpg") #Load the image
imagem = imagem.astype(np.float32) / 255.0  #Normalize to range [0, 1]
gamma = 2.2
imagem_gama = np.power(imagem, gamma) #Apply gamma correction
imagem = (imagem * 255).astype(np.uint8) #Scale back to [0, 255] and convert to uint8
imagem_gama = (imagem_gama * 255).clip(0, 255).astype(np.uint8)
                
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="BLUR_INT">
            <h2>Blur Integral</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">
import matplotlib.pyplot as plt
import numpy as np

def integral_image(imagem_gray):
    integral_img = np.zeros_like(imagem_gray)

    # Primeiro pixel
    integral_img[0, 0] = imagem_gray[0, 0]

    # Primeira linha
    for j in range(1, imagem_gray.shape[1]):
        integral_img[0, j] = integral_img[0, j-1] + imagem_gray[0, j]

    # Primeira coluna
    for i in range(1, imagem_gray.shape[0]):
        integral_img[i, 0] = integral_img[i-1, 0] + imagem_gray[i, 0]

    # Restantes pixeis 
    for i in range(1, imagem_gray.shape[0]):
        for j in range(1, imagem_gray.shape[1]):
            integral_img[i, j] = imagem_gray[i, j] + integral_img[i-1, j] + integral_img[i, j-1] - integral_img[i-1, j-1]

    return integral_img

def soma_regiao_integral(integral_img, x1, y1, x2, y2):
    total = integral_img[y2, x2]

    if x1 > 0:
        total -= integral_img[y2, x1 - 1]
    if y1 > 0:
        total -= integral_img[y1 - 1, x2]
    if x1 > 0 and y1 > 0:
        total += integral_img[y1 - 1, x1 - 1]

    return total

def blur(imagem_gray, integral_img, window_size):
    blurred_image = np.zeros_like(imagem_gray)
    half_window = window_size // 2

    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            x1 = j - half_window
            if x1 < 0: x1 = 0
            
            y1 = i - half_window
            if y1 < 0: y1 = 0
            
            x2 = j + half_window
            if x2 >= imagem_gray.shape[0]: x2 = imagem_gray.shape[0] - 1
            
            y2 = i + half_window
            if y2 >= imagem_gray.shape[1]: y2 = imagem_gray.shape[1] - 1
            
            blurred_image[i, j] = soma_regiao_integral(integral_img, x1, y1, x2, y2) / ((x2 - x1 + 1) * (y2 - y1 + 1))

    return blurred_image

imagem = plt.imread("barco.jpg")
height, width  , channel = imagem.shape 
imagem_gray= np.mean(imagem,axis=2) #Torna imagem em gray scale 
integral_img  = integral_image(imagem_gray)
blurred_img = blur(imagem_gray, integral_img ,30)
                
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="BLUR_GAUSS">
            <h2>Blurr Gaussiano</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">
import matplotlib.pyplot as plt
import numpy as np
def gaussian(imagem_gray):
    gaussian_matrix = np.array([[1, 4, 6, 4, 1],
                                [4, 16, 24, 16, 4],
                                [6, 24, 36, 26, 6],
                                [4, 16, 24, 16, 4],
                                [1, 4, 6, 4, 1]])

    filtered_img = np.zeros_like(imagem_gray)
    window_height, window_width = gaussian_matrix.shape

    padded_image = np.pad(imagem_gray, 
                            ((window_height // 2, window_height // 2), 
                            (window_width // 2, window_width // 2)),
                            mode='constant', constant_values=0)
    total = np.sum(gaussian_matrix)
    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+window_height, j:j+window_width]
            filtered_img[i, j] = np.sum(window * gaussian_matrix) / total
    
    return filtered_img

def sharpen(imagem_gray):
    # Define the sharpening filter (kernel)
    sharpening_kernel = np.array([[0, -1,  0],
                                    [-1,  5, -1],
                                    [0, -1,  0]])

    filtered_img = np.zeros_like(imagem_gray)
    window_height, window_width = sharpening_kernel.shape

    padded_image = np.pad(imagem_gray, 
                            ((window_height // 2, window_height // 2), 
                            (window_width // 2, window_width // 2)),
                            mode='constant', constant_values=0)

    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+window_height, j:j+window_width]
            
            filtered_img[i, j] = np.sum(window * sharpening_kernel)
    
    return filtered_img

def equation_sharpe(imagem_gray , blurred_img ):
    alpha = 0.5
    return (imagem_gray + alpha*(imagem_gray-blurred_img))

imagem = plt.imread("PCB.jpg")
imagem_gray= np.mean(imagem,axis=2) #Torna imagem em gray scale 
blurred_img = gaussian(imagem_gray)

#sharpened_img = sharpen(blurred_img)
sharpened_img = equation_sharpe(imagem_gray , blurred_img )
                
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="Sobel">
            <h2>Filtro de Sobel</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="codeBox5" class="codeBox">
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.image import imread

def apply_sobel_filter(image):
    """
    Aplica o filtro de Sobel a uma imagem.
    :param image: Imagem em escala de cinza como array numpy.
    :return: Magnitude do gradiente após a aplicação do filtro de Sobel.
    """
    # Define os kernels de Sobel
    sobel_x = np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]])
    sobel_y = np.array([[-1, -2, -1],
                        [ 0,  0,  0],
                        [ 1,  2,  1]])
    
    # Obtém as dimensões da imagem
    h, w = image.shape
    # Cria um array para armazenar o gradiente
    gradient_x = np.zeros_like(image)
    gradient_y = np.zeros_like(image)
    
    # Aplica o filtro de Sobel (evita bordas para simplificar)
    for i in range(1, h-1):
        for j in range(1, w-1):
            region = image[i-1:i+2, j-1:j+2]
            gradient_x[i, j] = np.sum(region * sobel_x)
            gradient_y[i, j] = np.sum(region * sobel_y)
    
    # Calcula a magnitude do gradiente
    magnitude = np.sqrt(gradient_x**2 + gradient_y**2)
    magnitude = (magnitude / np.max(magnitude) * 255).astype(np.uint8)  # Normaliza para 0-255
    
    return magnitude

# Carrega a imagem e converte para escala de cinza
image = imread('caminho_para_sua_imagem.jpg')
if image.ndim == 3:  # Caso seja RGB
    image = np.mean(image, axis=2)

# Aplica o filtro de Sobel
sobel_result = apply_sobel_filter(image)

# Mostra os resultados
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Imagem Original')
plt.imshow(image, cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title('Filtro de Sobel')
plt.imshow(sobel_result, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

                
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        
         
        <text class="titulo">Tarefas:</text>
         
        
        <section id="Radon">
            <h2>Transformada de Radon</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Radon" class="codeBox">
import numpy as np
import matplotlib.pyplot as plt


# Função para calcular as projeções horizontal e vertical
def calculate_projections(image):
    horizontal_projection = np.sum(image, axis=1)  # Soma ao longo das linhas para projeção horizontal
    vertical_projection = np.sum(image, axis=0)    # Soma ao longo das colunas para projeção vertical
    return horizontal_projection, vertical_projection

# Função para realizar a retroprojeção
def back_projection(horizontal_proj, vertical_proj, image_shape):
    reconstructed_image = np.zeros(image_shape)
    
    # Adiciona a projeção horizontal na imagem reconstruída
    for i in range(horizontal_proj.shape[0]):
        reconstructed_image[i, :] += horizontal_proj[i] / image_shape[1]

    # Adiciona a projeção vertical na imagem reconstruída
    for j in range(vertical_proj.shape[0]):
        reconstructed_image[:, j] += vertical_proj[j] / image_shape[0]

    # Ajusta os valores de intensidade
    reconstructed_image = np.where(reconstructed_image > 1.02, 1.0, 0.0)
   
    return reconstructed_image

# Carregar a imagem
image = plt.imread("triangulo.png")

# Converter a imagem para tons de cinza, se necessário
image = np.mean(image, axis=2)

# Calcular projeções
horizontal_proj, vertical_proj = calculate_projections(image)

# Realizar a retroprojeção
reconstructed_image = back_projection(horizontal_proj, vertical_proj, image.shape)

# Plotagem dos resultados
fig, axes = plt.subplots(2, 2, figsize=(10, 8))
ax = axes.ravel()

# Imagem Original
ax[0].imshow(image, cmap='gray')
ax[0].set_title('Imagem Original')
ax[0].axis('off')

# Projeção Horizontal
ax[1].plot(horizontal_proj, range(horizontal_proj.shape[0]), color='black')
ax[1].invert_yaxis()  # Inverter o eixo Y para corresponder à imagem
ax[1].set_title('Projeção Horizontal')
ax[1].set_xlabel('Intensidade')
ax[1].set_ylabel('Linha')

# Projeção Vertical
ax[2].plot(range(vertical_proj.shape[0]), vertical_proj, color='black')
ax[2].set_title('Projeção Vertical')
ax[2].set_xlabel('Coluna')
ax[2].set_ylabel('Intensidade')

# Imagem Reconstruída
ax[3].imshow(reconstructed_image, cmap='gray')
ax[3].set_title('Imagem Reconstruída')
ax[3].axis('off')

plt.tight_layout()
plt.show()
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="Integral">
            <h2>Integral de uma Imagem</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Integral" class="codeBox">
import matplotlib.pyplot as plt
import numpy as np

def integral_image(imagem_gray):
    """
    Calcula a imagem integral de uma imagem em escala de cinza.

    A imagem integral é uma representação que permite calcular a soma dos valores de pixel em uma
    região retangular da imagem em tempo constante (O(1)).

    Parâmetros:
    imagem_gray (numpy.ndarray): Imagem em escala de cinza (2D).

    Retorna:
    numpy.ndarray: A imagem integral correspondente à imagem de entrada.
    """
    integral_img = np.zeros_like(imagem_gray)

    # Primeira célula
    integral_img[0, 0] = imagem_gray[0, 0]
    
    # Primeira linha
    for j in range(1, imagem_gray.shape[1]):
        integral_img[0, j] = integral_img[0, j-1] + imagem_gray[0, j]

    # Primeira coluna
    for i in range(1, imagem_gray.shape[0]):
        integral_img[i, 0] = integral_img[i-1, 0] + imagem_gray[i, 0]

    # Preencher o restante da matriz de soma acumulada
    for i in range(1, imagem_gray.shape[0]):
        for j in range(1, imagem_gray.shape[1]):
            integral_img[i, j] = imagem_gray[i, j] + integral_img[i-1, j] + integral_img[i, j-1] - integral_img[i-1, j-1]
    
    return integral_img

def soma_regiao_integral(integral_img, x1, y1, x2, y2):
    """
    Calcula a soma dos valores de pixel em uma região retangular da imagem usando a imagem integral.

    A soma é calculada com base nas coordenadas do canto superior esquerdo (x1, y1) e do canto inferior
    direito (x2, y2).

    Parâmetros:
    integral_img (numpy.ndarray): A imagem integral da qual a soma será calculada.
    x1 (int): Coordenada x do canto superior esquerdo.
    y1 (int): Coordenada y do canto superior esquerdo.
    x2 (int): Coordenada x do canto inferior direito.
    y2 (int): Coordenada y do canto inferior direito.

    Retorna:
    float: A soma dos valores de pixel na região especificada.
    """
    total = integral_img[y2, x2]
    
    if x1 > 0:
        total -= integral_img[y2, x1 - 1]
    if y1 > 0:
        total -= integral_img[y1 - 1, x2]
    if x1 > 0 and y1 > 0:
        total += integral_img[y1 - 1, x1 - 1]

    return total

# Carrega a imagem
imagem = plt.imread("barco.jpg")
height, width, channel = imagem.shape 

# Define as coordenadas do canto superior esquerdo e inferior direito da região de interesse
top_left = [400, 200]
bottom_right = [800, 800]

# Converte a imagem para escala de cinza
imagem_gray = np.mean(imagem, axis=2)

# Recorta a região de interesse da imagem em escala de cinza
cropped_imagem_gray = imagem_gray[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]] 

# Calcula a imagem integral da imagem em escala de cinza
integral_img = integral_image(imagem_gray)

# Calcula a soma da região usando a imagem integral
soma = soma_regiao_integral(integral_img, top_left[0], top_left[1], bottom_right[0], bottom_right[0])
print(f"Valor da soma = {soma}")

# Exibe as imagens
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.title("Imagem Original")
plt.imshow(imagem)
plt.subplot(1, 3, 2)
plt.imshow(imagem_gray, cmap="gray")
plt.title("Imagem em GrayScale")
plt.subplot(1, 3, 3)
plt.imshow(cropped_imagem_gray, cmap="gray")
plt.title("Imagem em GrayScale Cortada")
plt.show()

                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="Filtros">
            <h2>Filtros</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Filtros" class="codeBox">
import matplotlib.pyplot as plt
import numpy as np

def integral_image(imagem_gray):
    """
    Calcula a imagem integral de uma imagem em tons de cinza.

    Parâmetros:
    imagem_gray (np.array): Imagem em tons de cinza.

    Retorna:
    np.array: Imagem integral.
    """
    integral_img = np.zeros_like(imagem_gray)

    # Primeiro pixel
    integral_img[0, 0] = imagem_gray[0, 0]
    
    # Primeira linha
    integral_img[0, 1:] = np.cumsum(imagem_gray[0, 1:], axis=0) + imagem_gray[0, 0]

    # Primeira coluna
    integral_img[1:, 0] = np.cumsum(imagem_gray[1:, 0], axis=0) + imagem_gray[0, 0]

    # Restantes pixeis
    for i in range(1, imagem_gray.shape[0]):
        for j in range(1, imagem_gray.shape[1]):
            integral_img[i, j] = (imagem_gray[i, j] + integral_img[i-1, j] + 
                                  integral_img[i, j-1] - integral_img[i-1, j-1])
    
    return integral_img

def soma_regiao_integral(integral_img, x1, y1, x2, y2):
    """
    Calcula a soma dos valores em uma região da imagem integral.

    Parâmetros:
    integral_img (np.array): Imagem integral.
    x1, y1 (int): Coordenadas do canto superior esquerdo da região.
    x2, y2 (int): Coordenadas do canto inferior direito da região.

    Retorna:
    int: Soma dos valores na região especificada.
    """
    total = integral_img[y2, x2]
    
    if x1 > 0:
        total -= integral_img[y2, x1 - 1]
    if y1 > 0:
        total -= integral_img[y1 - 1, x2]
    if x1 > 0 and y1 > 0:
        total += integral_img[y1 - 1, x1 - 1]

    return total

def filtro_média(imagem_gray, integral_img, window_size):
    """
    Aplica um filtro de média usando a imagem integral.

    Parâmetros:
    imagem_gray (np.array): Imagem em tons de cinza.
    integral_img (np.array): Imagem integral.
    window_size (int): Tamanho da janela para o filtro de média.

    Retorna:
    np.array: Imagem filtrada.
    """
    média_image = np.zeros_like(imagem_gray)
    half_window = window_size // 2
    
    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            x1 = max(0, j - half_window)
            y1 = max(0, i - half_window)
            x2 = min(imagem_gray.shape[1] - 1, j + half_window)
            y2 = min(imagem_gray.shape[0] - 1, i + half_window)
            
            média_image[i, j] = (soma_regiao_integral(integral_img, x1, y1, x2, y2) / 
                                 ((x2 - x1 + 1) * (y2 - y1 + 1)))
    
    return média_image

def apply_prewitt(imagem_gray, kernel):
    """
    Aplica um filtro Prewitt na imagem em tons de cinza.

    Parâmetros:
    imagem_gray (np.array): Imagem em tons de cinza.
    kernel (np.array): Kernel Prewitt para o filtro.

    Retorna:
    np.array: Imagem filtrada.
    """
    filtered_img = np.zeros_like(imagem_gray)
    padded_image = np.pad(imagem_gray, 1, mode='constant', constant_values=0)
    
    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+3, j:j+3]
            filtered_img[i, j] = np.sum(window * kernel)
    return filtered_img

def combined_filter(imagem_gray):
    """
    Combina filtros Prewitt em quatro direções (0, 45, 90 e 135 graus).

    Parâmetros:
    imagem_gray (np.array): Imagem em tons de cinza.

    Retorna:
    np.array: Imagem filtrada combinada.
    """
    kernels = {
        "0G": np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]),
        "45G": np.array([[-1, -1, 0], [-1, 0, 1], [0, 1, 1]]),
        "90G": np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]),
        "135G": np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])
    }
    
    filtered_images = [apply_prewitt(imagem_gray, kernel) for kernel in kernels.values()]
    return sum(np.abs(img) for img in filtered_images)

def gaussian(imagem_gray):
    """
    Aplica um filtro Gaussiano na imagem em tons de cinza.

    Parâmetros:
    imagem_gray (np.array): Imagem em tons de cinza.

    Retorna:
    np.array: Imagem filtrada.
    """
    gaussian_matrix = np.array([[1, 4, 6, 4, 1],
                                [4, 16, 24, 16, 4],
                                [6, 24, 36, 24, 6],
                                [4, 16, 24, 16, 4],
                                [1, 4, 6, 4, 1]])
    gaussian_matrix = gaussian_matrix / np.sum(gaussian_matrix)

    filtered_img = np.zeros_like(imagem_gray)
    padded_image = np.pad(imagem_gray, 2, mode='constant', constant_values=0)
    
    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+5, j:j+5]
            filtered_img[i, j] = np.sum(window * gaussian_matrix)
    
    return filtered_img

def equation_sharpe(imagem_gray, blurred_img):
    """
    Aplica um filtro de nitidez na imagem usando uma imagem borrada.

    Parâmetros:
    imagem_gray (np.array): Imagem original em tons de cinza.
    blurred_img (np.array): Imagem borrada.

    Retorna:
    np.array: Imagem com nitidez aumentada.
    """
    alpha = 1.5
    return imagem_gray + alpha * (imagem_gray - blurred_img)

# Leitura e exibição das imagens
imagem = plt.imread("../imagens/pcb.jpg")
imagem_gray = np.mean(imagem, axis=2)

integral_img = integral_image(imagem_gray)
N = 5
média_imagem = filtro_média(imagem_gray, integral_img, N)
prewitt_imagem = combined_filter(imagem_gray)
gaussian_imagem = gaussian(imagem_gray)
sharp_imagem = equation_sharpe(imagem_gray, média_imagem)

plt.figure(figsize=(15, 10))
plt.subplot(2, 3, 1)
plt.title("Imagem Original")
plt.imshow(imagem)

plt.subplot(2, 3, 2)
plt.title("Imagem para níveis de cinzento")
plt.imshow(imagem_gray, cmap='gray')

plt.subplot(2, 3, 3)
plt.title(f"Filtro de Média NxN (5x5)")
plt.imshow(média_imagem, cmap='gray')

plt.subplot(2, 3, 4)
plt.title("Filtro Prewitt")
plt.imshow(prewitt_imagem, cmap='gray')

plt.subplot(2, 3, 5)
plt.title("Filtro Gaussiano")
plt.imshow(gaussian_imagem, cmap='gray')

plt.subplot(2, 3, 6)
plt.title("Imagem com Nitidez Aumentada")
plt.imshow(sharp_imagem, cmap='gray')

plt.tight_layout()
plt.show()


                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>

        <section id="Arucos">
            <h2>Arucos</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Arucos" class="codeBox">
"""
O objetivo deste trabalho consiste em identificar os marcadores ARUCo presentes na imagem (imagem 1)  em anexo, através dos seguintes passos:
1 - Segmentar a imagem (extrair pixeis escuros) (imagem 2)
2 - Remover ruído utilizando operadores morfológicos (imagem 3)
3 - Fazer labeling à imagem (identificar os blobs) (imagem 4)
4 - Extrair as subimagens de cada maracador ARUCO através dos valores de área dos blobs (imagem 5)
5 - Para cada marcador, extrair a palavra binária (imagem 6)
6 - Identificar os marcadores através do dicionário seguinte (imagem 7):
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1],  # USV
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0],  # ASV
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0],  # ROV
        [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1],  # AAV
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # UUV
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0],  # UAV
"""

import matplotlib.pyplot as plt
import numpy as np
import scipy.ndimage as sc

img = plt.imread("aruco01.png")
img_gray = np.mean(img, axis=2)
img_gray = img_gray < 0.5

img_dil = sc.binary_dilation(img_gray, structure=np.ones([3, 3]))
img_erode = sc.binary_erosion(img_dil, structure=np.ones([7, 7]))
img_final = sc.binary_dilation(img_erode, structure=np.ones([4, 4]))

labeled_img, num_features = sc.label(img_final)

excentricidades = []
rectangular_marker_imgs = []
bouding_marker_imgs = []


for k in range(1, num_features + 1):
    M00 = M01 = M10 = 0

    for i in range(labeled_img.shape[0]):
        for j in range(labeled_img.shape[1]):
            M00 += (labeled_img[i, j] == k).astype(int)
            M01 += (labeled_img[i, j] == k).astype(int) * j
            M10 += (labeled_img[i, j] == k).astype(int) * i

    if M00 == 0:  
        continue

    y = M01 / M00 
    x = M10 / M00  

    mu11 = mu02 = mu20 = 0
    for i in range(labeled_img.shape[0]):
        for j in range(labeled_img.shape[1]):
            mu11 += (i - x) * (j - y) * (labeled_img[i, j] == k).astype(int)
            mu02 += (j - y) ** 2 * (labeled_img[i, j] == k).astype(int)
            mu20 += (i - x) ** 2 * (labeled_img[i, j] == k).astype(int)

    cov_matrix = np.array([[mu20, mu11], [mu11, mu02]])
    eigenvalues, _ = np.linalg.eig(cov_matrix)
    lambda_max, lambda_min = np.sort(eigenvalues)[::-1]

    if lambda_max == 0:
        excentricidade = 0
    else:
        excentricidade = np.sqrt(1 - (lambda_min / lambda_max))

    excentricidades.append(excentricidade)

    if excentricidade < 0.5 and excentricidade > 0.0:
        rows, cols = np.where(labeled_img == k)
        min_row, max_row = rows.min(), rows.max()
        min_col, max_col = cols.min(), cols.max()
        
        bouding_marker_imgs.append((min_row, max_row , min_col, max_col))
        
        sub_img = img_final[min_row:max_row + 1, min_col:max_col + 1]
        rectangular_marker_imgs.append((sub_img, excentricidade))


#Ler aruco
def extrair_palavra_binaria(marker_img, grid_size=(6, 6) , inner_size=(4, 4) ):
    """
    Extrai uma representação binária de um marcador ARUCO a partir de uma subimagem.

    Parâmetros:
    marker_img (ndarray): A subimagem do marcador.
    grid_size (tuple): Tamanho da grade externa (6x6 por padrão).
    inner_size (tuple): Tamanho da grade interna (4x4 por padrão).

    Retorna:
    str: Uma string binária representando a área interna 4x4 do marcador.
    """
    rows, cols = marker_img.shape
    cell_height = rows // grid_size[0]
    cell_width = cols // grid_size[1]
    
    # Define as bordas da área 4x4 dentro da 6x6
    start_row = (grid_size[0] - inner_size[0]) // 2
    start_col = (grid_size[1] - inner_size[1]) // 2
    
    word = ""
    for i in range(start_row, start_row + inner_size[0]):
        for j in range(start_col, start_col + inner_size[1]):
            # Extrai uma célula da grade
            cell = marker_img[i*cell_height:(i+1)*cell_height, j*cell_width:(j+1)*cell_width]
            cell_mean = np.mean(cell)
            if cell_mean > 0.6:
                word += "1" 
            else: 
                word += "0"  
    
    return word

markers_dicionary = [
    (np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1]), "USV"),
    (np.array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0]), "ASV"),
    (np.array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0]), "ROV"),
    (np.array([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]), "AAV"),
    (np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), "UUV"),
    (np.array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]), "UAV")
]

palavras_bins =[]
for i in range(len(rectangular_marker_imgs)):
    (marker_img, ecc) = rectangular_marker_imgs[i]
    
    palavra_bin_str = extrair_palavra_binaria(marker_img)
    print(f"Palavra binaria do marcador {i+1} = {palavra_bin_str}")
    
    palavra_bin = [int(bit) for bit in palavra_bin_str]
    palavras_bins.append(palavra_bin)
    

# Display the original images and processed stages
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
plt.imshow(img)
plt.title("Imagem Original (1)")

plt.subplot(2, 3, 2)
plt.imshow(img_gray)
plt.title("Imagem Binário (2)")

plt.subplot(2, 3, 3)
plt.imshow(img_final)
plt.title("Imagem Sem Ruído")

plt.subplot(2, 3, 4)
plt.imshow(labeled_img)
plt.title("Objetos com Label")

plt.subplot(2, 3, 5)
plt.imshow(img)
for i in range(len(palavras_bins)):
    (marker_img, ecc) = rectangular_marker_imgs[i]
    
    min_row, max_row , min_col, max_col = bouding_marker_imgs[i]
    
    plt.plot([min_col, max_col, max_col, min_col, min_col], 
            [min_row, min_row, max_row, max_row, min_row], color='red', linewidth=2)
    plt.title(f"Subimagens de cada maracador ARUCO (5)")
    
    for bin_array, marker_name in markers_dicionary:
        if np.array_equal(palavras_bins[i], bin_array):
            plt.text(min_col, min_row, marker_name, color="Black", size=10)
            break 

# Display each extracted rectangular marker
for i in range(len(rectangular_marker_imgs)):
    (marker_img, ecc) = rectangular_marker_imgs[i]
    plt.figure()
    plt.imshow(marker_img)
    plt.title(f"Marcador {i+1} (excentricidade: {ecc:.2f}) (6)")
    plt.axis('off')


plt.tight_layout()
plt.show()

                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button> 
            </div>
        </section>


        <section id="Calibrar_Camera">
            <h2>Calibrar Camera</h2>
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Calibrar_Camera" class="codeBox">
import cv2
import glob
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors


def Detetar_cantos(num_images,images):
    cantos=np.zeros([num_images,4,2])
    for i in range(num_images):
        fname = images[i]
        print('Processing {}'.format(fname))
        
        I = cv2.imread(fname)
        hsv = cv2.cvtColor(I, cv2.COLOR_BGR2HSV)
        Ibw = (hsv[:, :, 1] > 100) * (hsv[:, :, 0] < 70) * (hsv[:, :, 0] > 55) * (I[:, :, 0] > 10) * (I[:, :, 1] > 10)
        Ibw = Ibw.astype(np.uint8) * 255
        
        Ibw = cv2.dilate(Ibw, np.ones((7, 7)))
        Ibw = cv2.erode(Ibw, np.ones((13, 13)))
        colored_image = cv2.cvtColor(Ibw, cv2.COLOR_GRAY2BGR)
        
        # Encontrar contornos
        contornos, _ = cv2.findContours(Ibw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Encontrar o maior contorno
        maior_contorno = max(contornos, key=cv2.contourArea)

        # Desenhar o maior contorno em verde
        I_cantos = I.copy()
        cv2.drawContours(colored_image, [maior_contorno], -1, (0, 255, 0), 25)

        # Aproximar o contorno para encontrar os cantos
        epsilon = 0.1 * cv2.arcLength(maior_contorno, True)
        approx = cv2.approxPolyDP(maior_contorno, epsilon, True)
        
        # Separar pontos superiores e inferiores com base em suas coordenadas y
        pontos = sorted(approx.reshape(4, 2), key=lambda x: x[1])  # Ordenar por y
        pontos_superiores = sorted(pontos[:2], key=lambda x: x[0])  # Ordenar os dois pontos superiores por x
        pontos_inferiores = sorted(pontos[2:], key=lambda x: x[0], reverse=True)  # Ordenar os dois inferiores por x

        # cantos ordenados: superior-esquerdo, superior-direito, inferior-direito, inferior-esquerdo
        cantos_ordenados = np.array(pontos_superiores + pontos_inferiores, dtype="float32")


        cantos[i]=cantos_ordenados
        # Desenhar os cantos do maior contorno
        for ponto in cantos_ordenados:
            x, y = ponto.ravel()
            cv2.circle(colored_image, (int(x), int(y)), 35, (0, 0, 255), -1)

        # Adicionar imagem ao subplot
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(colored_image, cv2.COLOR_BGR2RGB))
        plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    plt.figure()
    
    return cantos


def get_warped_img(num_images,images,cantos):
    molduraThickness=1.5 #1.5 squares
    boardSquares=np.array([15,29])
    resolution=50
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)
    pts_destino = np.array([[0, 0], [warpedSize[1], 0], [warpedSize[1], warpedSize[0]], [0, warpedSize[0]]], dtype='float32')

    M=np.zeros([num_images,3,3])

    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')
        
        # Carregar imagem
        I = cv2.imread(fname)
        
        # Calcular a matriz de transformação projetiva
        M[i] = cv2.getPerspectiveTransform(np.array(cantos[i], dtype='float32'), pts_destino)

        # Aplicar a transformação para obter a imagem transformada
        warped_image = cv2.warpPerspective(I, M[i], (warpedSize[1], warpedSize[0]))
    
        # Adicionar a imagem ao subplot
        plt.subplot(5, 4, i + 1)
        plt.imshow(cv2.cvtColor(warped_image, cv2.COLOR_BGR2RGB))  # Converter de volta para RGB para exibição
        plt.axis('off')
        
    plt.tight_layout()
    plt.show()
    plt.figure()
    
    return M


def get_centroids_of_black_squares(num_images,images,M):
    molduraThickness=1.5 #1.5 squares
    boardSquares=np.array([15,29])
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    resolution=50
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)
    stats_centroides=np.zeros([num_images,2*reducedSquares[0]*reducedSquares[1]-reducedSquares[0]-reducedSquares[1]+1,2])

    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')
        
        # Carregar imagem
        I = cv2.imread(fname)

        # Aplicar a transformação para obter a imagem transformada
        warped_image = cv2.warpPerspective(I, M[i], (warpedSize[1], warpedSize[0]))

        # Segmentação por threshold adaptativo
        gray_warped = warped_image[:, :, 1]
        bw_warped = cv2.adaptiveThreshold(gray_warped, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 111, 1)

        # Centroides dos quadrados pretos
        Iwhite = cv2.dilate(bw_warped, np.ones((9, 9)))  # Dilatar para melhorar a detecção
        Iblack = 255 - Iwhite  # Inverter a imagem binária (para os quadrados brancos se tornarem pretos)

        # Criar uma cópia colorida para desenhar os círculos
        colored_image = cv2.cvtColor(Iwhite, cv2.COLOR_GRAY2BGR)
        
        # Encontrar componentes conectados
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(Iblack)
        
        # Filtrar os quadrados com base em largura e altura
        filtered_centroids = []
        for j in range(1, num_labels):  # Começar de 1 para ignorar o fundo (label 0)
            x, y, w, h, area = stats[j]
            
            # Verificar se a largura e altura estão no intervalo desejado
            if resolution - 20 < w < resolution and resolution - 20 < h < resolution:
                filtered_centroids.append(centroids[j])  # Adicionar os stats do quadrado que atende aos critérios
        
        # Converter a lista de stats filtrados para um array
        stats_centroides[i] = np.array(filtered_centroids)

        for centroid in filtered_centroids:  
            center_x, center_y = centroid  # Usar diretamente as coordenadas (x, y)

            # Desenhar um círculo verde no centroide
            cv2.circle(colored_image, (int(center_x), int(center_y)), 11, (0, 0, 255), -1)  # Círculo preenchido de verde


        # Adicionar a imagem ao subplot
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(colored_image, cv2.COLOR_BGR2RGB))  # Converter de volta para RGB para exibição
        plt.axis('off')
        
    plt.tight_layout()
    plt.show()
    plt.figure()
    
    return stats_centroides

def filtrar_e_ordenar_centroid_com_KNN(num_images,images,M,stats_centroides):
    resolution=50
    molduraThickness=1.5 #1.5 squares
    boardSquares=np.array([15,29])
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    grid_rows, grid_cols = reducedSquares[0],reducedSquares[1]
    warped_centroids=np.zeros([num_images,reducedSquares[0]*reducedSquares[1],2])
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)

    # Loop sobre as imagens
    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')

        # Carregar imagem
        I = cv2.imread(fname)

        # Aplicar a transformação para obter a imagem transformada
        warped_image = cv2.warpPerspective(I, M[i], (warpedSize[1], warpedSize[0]))

        # Segmentação por threshold adaptativo
        gray_warped = warped_image[:, :, 1]
        bw_warped = cv2.adaptiveThreshold(gray_warped, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 111, 1)

        # Centroides dos quadrados pretos
        Iwhite = cv2.dilate(bw_warped, np.ones((9, 9)))  # Dilatar para melhorar a detecção
        Iblack = 255 - Iwhite  # Inverter a imagem binária (para os quadrados brancos se tornarem pretos)

        # Criar uma cópia colorida para desenhar os círculos
        colored_image = cv2.cvtColor(Iwhite, cv2.COLOR_GRAY2BGR)


        # Ajustar o modelo KNN com os centroides filtrados
        knn = NearestNeighbors(n_neighbors=1).fit(stats_centroides[i])

        # Desenhar os centroides
        for centroid in stats_centroides[i]:  
            center_x, center_y = centroid  # Usar diretamente as coordenadas (x, y)

            # Desenhar um círculo verde no centroide
            cv2.circle(colored_image, (int(center_x), int(center_y)), 10, (50, 50, 50), -1)  # Círculo preenchido de verde

        # Encontrar limites da grelha
        x_min, y_min = np.min(stats_centroides[i], axis=0)
        x_max, y_max = np.max(stats_centroides[i], axis=0)

        # Definir o espaçamento da grelha
        grid_x_spacing = (x_max - x_min) / (grid_cols - 1)
        grid_y_spacing = (y_max - y_min) / (grid_rows - 1)

        # Gerar nós da grelha
        
        grid_nodes = []
        idx=0
        for row in range(grid_rows):
            for col in range(grid_cols):
                grid_x = int(x_min + col * grid_x_spacing)
                grid_y = int(y_min + row * grid_y_spacing)
                grid_nodes.append([grid_x, grid_y])
                #cv2.circle(colored_image, (grid_x, grid_y), 10, (0, 128, 255), -1)  # Nó da grelha em azul

                # Desenhar linhas verticais (exceto para o último nó de cada coluna)
                if col < grid_cols - 1:
                    next_x = int(x_min + (col+1) * grid_x_spacing)
                    cv2.line(colored_image, (grid_x, grid_y), (next_x, grid_y), (0, 0, 100), 2)

                # Desenhar linhas horizontais (exceto para o último nó de cada linha)
                if row < grid_rows - 1:
                    next_y = int(y_min + (row+1) * grid_y_spacing)
                    cv2.line(colored_image, (grid_x, grid_y), (grid_x, next_y), (0, 0, 100), 2)
                    
                distance, nearest_index = knn.kneighbors([(grid_x, grid_y)])
                nearest_centroid = stats_centroides[i][nearest_index[0][0]]
                
                warped_centroids[i,idx] = nearest_centroid
                idx=idx+1
                
                center_x, center_y = nearest_centroid  # Usar diretamente as coordenadas (x, y)
                cv2.circle(colored_image, (int(center_x), int(center_y)), 11, (0, 0, 255), -1)  # Círculo preenchido de verde

                # Desenhar uma linha conectando o nó da grelha ao centroide mais próximo
                center_x, center_y = nearest_centroid
                cv2.line(colored_image, (grid_x, grid_y), (int(center_x), int(center_y)), (0, 255, 0), 3)


        # Adicionar a imagem ao subplot
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(colored_image, cv2.COLOR_BGR2RGB))
        plt.axis('off')

    # Exibir as imagens com os centroides e a grelha sobrepostos
    plt.tight_layout()
    plt.show()
    plt.figure()

    return warped_centroids


def por_centroids_na_img_original(num_images,images,warped_centroids):
    molduraThickness=1.5 #1.5 squares
    resolution=50
    boardSquares=np.array([15,29])
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)
    pts_destino = np.array([[0, 0], [warpedSize[1], 0], [warpedSize[1], warpedSize[0]], [0, warpedSize[0]]], dtype='float32')
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    centroides_reais=np.zeros([num_images,reducedSquares[0]*reducedSquares[1],2])
    
    # Loop sobre as imagens
    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')

        # Carregar imagem
        I = cv2.imread(fname)

        # Transformar os centróides para coordenadas reais usando a matriz de homografia
        c = warped_centroids[i].reshape(warped_centroids[i].shape[0], 1, 2)
        h = cv2.findHomography(pts_destino.astype('float32'), cantos[i].astype('float32'))[0]
        #h = np.linalg.inv(M[i])
        centroides_reais[i] = cv2.perspectiveTransform(c, h).squeeze()

        # Desenhar os centroides reais
        for (x, y) in centroides_reais[i]:
            # Desenhar um círculo em cada centroide
            cv2.circle(I, (int(x), int(y)), 25, (0, 0, 255), -1)  # Círculo verde

        # Mostrar a imagem com os centroides desenhados
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))
        plt.axis('off')

    plt.tight_layout()
    plt.show()
    plt.figure()

    return centroides_reais

def calibarar_camera(num_images,images,centroides_reais):
    boardSquares=np.array([15,29])
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    camsize = cv2.imread(images[0]).shape
    NY = reducedSquares[0]
    NX = reducedSquares[1]
    objp = np.zeros((NY * NX, 3), np.float32)
    objp[:, :2] = np.mgrid[0:NX, 0:NY].T.reshape(-1, 2)
    imgpoints = [centroides_reais[i].reshape(-1, 1, 2).astype('single') for i in range(len(centroides_reais))]
    objpoints = [objp.astype('single') for i in range(len(centroides_reais))]
    calibration_stop_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 1000, 1e-9)

    # Calibracao da camara
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (camsize[1], camsize[0]), None, None, None, calibration_stop_criteria)
    print(np.array2string(mtx, formatter={'float_kind':lambda x: f"{x:.2f}"}))

    # Calcular matriz da camara optimizada (alpha=0 para manter o máximo do campo de visão sem bordas, alpha=1 para mostrar campo de visão completo)
    mtx_opt0, roi0 = cv2.getOptimalNewCameraMatrix(mtx, dist, (camsize[1], camsize[0]), alpha=0)
    mtx_opt1, roi1 = cv2.getOptimalNewCameraMatrix(mtx, dist, (camsize[1], camsize[0]), alpha=1)

    # Correção das imagens

    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')
        
        # Carregar imagem original
        I = cv2.imread(fname)

        # Corrigir distorção sem corte
        corrI = cv2.undistort(I, mtx, dist, None, mtx_opt1)

        # Mostrar a imagem corrigida
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(corrI, cv2.COLOR_BGR2RGB))
        plt.axis('off')

    plt.tight_layout()
    plt.show()
       

nome = 'calibracao'
images = glob.glob(nome + '/*.jpg')
num_images = len(images)
cols = 4  # Número de colunas desejado
rows = (num_images // cols) + (num_images % cols > 0)  # Calcula o número de linhas

# Passo #0: Ler as imagens
plt.figure()
for i in range(num_images):
    fname = images[i]
    print('Processing {}'.format(fname))
    
    I = cv2.imread(fname)

    # Adicionar imagem ao subplot
    plt.subplot(rows, cols, i + 1)
    plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))
    plt.axis('off')

plt.tight_layout()
plt.show()
plt.figure()

cantos = Detetar_cantos(num_images,images)
M = get_warped_img(num_images,images,cantos)
centroides = get_centroids_of_black_squares(num_images,images,M)
filtered_centroid = filtrar_e_ordenar_centroid_com_KNN(num_images,images,M,centroides)
centroides_reais = por_centroids_na_img_original(num_images,images,filtered_centroid)
calibarar_camera(num_images,images,centroides_reais)
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
        </section>

        <text class="titulo">Exercícios de Treino para o Teste:</text>

        <section id="Exercicio1">
            <h2>Exercício 1</h2>
            <section id="teoria">
                <article>
                    O código começa por carregar uma imagem a partir de um ficheiro JPEG utilizando a função `plt.imread("imagem.jpeg")` e armazena os dados dessa imagem na variável `image`. A seguir, a imagem é convertida para escala de cinza através da operação `np.mean(image, axis=2)`, que calcula a média dos valores das cores ao longo do eixo 2 (RGB). Após a conversão, a imagem original e a imagem em escala de cinza são apresentadas lado a lado utilizando a biblioteca `matplotlib`. A imagem em escala de cinza é exibida com o mapa de cores "gray", o que a torna visível em tons de cinza.
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
"""
Exercicio 1 :
    --> Carregar uma imagem
    --> Converter a imagem para escala de cinza
    --> Mostrar a imagem
"""

import matplotlib.pyplot as plt
import numpy as np


image = plt.imread("imagem.jpeg")
imagem_pb = np.mean(image, axis=2)
                
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.title("Imagem Original")
plt.imshow(image)
plt.subplot(1, 2, 2)
plt.imshow(imagem_pb, cmap="gray")
plt.title("Imagem em GrayScale")

plt.show()
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>

            <section id="teoria">
                Output:
                <img src='./images/output_exe_1.png' style="width : 100%">
            </section>
        </section>


        <section id="Exercicio2">
            <h2>Exercício 2</h2>
            <section id="teoria">
                <article>
                    O código começa por carregar uma imagem a partir de um ficheiro JPEG utilizando a função `plt.imread("imagem_2.jpeg")`, normalizando os valores dos pixels dividindo por 255 para que fiquem no intervalo de 0 a 1. Em seguida, é realizada a segmentação da imagem com base na cor, criando uma máscara binária chamada `imagem_verde`, onde a condição especificada verifica se o valor do componente vermelho (R) é menor que 0.6, o valor do componente verde (G) é maior que 0.4 e o valor do componente azul (B) é menor que 0.6. A operação `astype(int)` converte o resultado da expressão booleana para 0s e 1s, gerando uma imagem binária. Finalmente, a imagem original e a imagem binária resultante da segmentação são exibidas lado a lado usando `matplotlib`, com títulos apropriados para cada uma.
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
""" 
Exercicio 2:
    --> Carregar uma imagem
    --> Segmentar por côr
    --> Mostrar imagem binária
"""

import matplotlib.pyplot as plt
import numpy as np


image = plt.imread("imagem_2.jpeg")/255
imagem_verde = ((image[:,:,0]<0.6)*(image[:,:,1]>0.4)*(image[:,:,2]<0.6)).astype(int)

            
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.title("Imagem Original")
plt.imshow(image)
plt.subplot(1, 2, 2)
plt.imshow(imagem_verde)
plt.title("Imagem Verde")

plt.show()
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <img src='./images/output_exe_2.png' style="width : 100%">
            </section>
        </section>


        <section id="Exercicio3">
            <h2>Exercício 3</h2>
            <section id="teoria">
                <article>
                    O código começa por carregar uma imagem a partir de um ficheiro JPEG utilizando a função `cv2.imread('imagem_2.jpeg')`. Em seguida, a imagem é convertida do espaço de cor BGR (utilizado pelo OpenCV) para o espaço HSV (matiz, saturação e valor) com a função `cv2.cvtColor(I, cv2.COLOR_BGR2HSV)`. Após a conversão, é realizada a segmentação da imagem para identificar áreas com predominância da cor verde, utilizando uma condição baseada nos valores dos canais B (azul), G (verde) e R (vermelho) no espaço BGR. A condição `((I[:,:,0]<150)*(I[:,:,1]>100)*(I[:,:,2]<150))` cria uma máscara binária, onde os pixels que satisfazem essas condições são marcados como 1 e os outros como 0. Finalmente, o código exibe três imagens lado a lado: a imagem original, a imagem convertida para o espaço HSV e a imagem binária resultante da segmentação verde.
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
""" 
Exercicio 3:
    --> Carregar uma imagem
    --> Segmentar por côr (no espaço HSV)
    --> Mostrar imagem binária
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt


I = cv2.imread('imagem_2.jpeg')
hsv = cv2.cvtColor(I, cv2.COLOR_BGR2HSV)

hsv_verde = ((I[:,:,0]<150)*(I[:,:,1]>100)*(I[:,:,2]<150)).astype(int)

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.title("Imagem Original")
plt.imshow(I)
plt.subplot(1, 3, 2)
plt.imshow(hsv)
plt.title("Imagem HSV")
plt.subplot(1, 3, 3)
plt.imshow(hsv_verde)
plt.title("Imagem HSV verde")

plt.show()
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <img src='./images/output_exe_3.png' style="width : 100%">
            </section>
        </section>

        <section id="Exercicio4">
            <h2>Exercício 4</h2>
            <section id="teoria">
                <article>
                    O código começa por carregar uma imagem de um parafuso a partir de um ficheiro PNG utilizando `plt.imread("parafuso.png")`. Em seguida, é realizada a segmentação da imagem com base nos valores dos pixels, considerando os pixels escuros (valores de cor abaixo de 0.9) como objetos, criando uma imagem binária chamada `imagem_segmentada`. Após a segmentação, o código utiliza a função `cv2.connectedComponentsWithStats` para identificar e rotular os componentes conectados na imagem, ou seja, os objetos segmentados. A seguir, calcula-se a excentricidade de cada componente através de seus momentos geométricos e da matriz de covariância, o que permite distinguir os parafusos de outros objetos com base na forma.
<br>
A excentricidade é usada para classificar os objetos, e é definido um limiar (0.8) para classificar os componentes com excentricidade superior a esse valor como "parafusos". Os rótulos dos parafusos detectados são armazenados em uma lista chamada `parafusos`. O código então exibe o número total de componentes e os rótulos dos parafusos identificados.
<br>
Finalmente, a segmentação é visualizada com a imagem original e a imagem resultante, onde os parafusos detectados são destacados em vermelho. Este processo inclui uma etapa opcional de operações morfológicas (não incluídas no código, mas mencionadas no enunciado).
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
"""
Exercicio 4:
    --> Carregar uma imagem
    --> Segmentar Imagem
    --> (opcional) Op. Morfológicas
    --> Contar Blobs/Contornos
    --> Separar parafusos
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Carregar imagem
image = plt.imread("parafuso.png")

# Segmentação da imagem (considerando pixels escuros como objetos)
imagem_segmentada = ((image[:, :, 0] < 0.9) * (image[:, :, 1] < 0.9) * (image[:, :, 2] < 0.9)).astype(np.uint8)

# Encontrar componentes conectados
num_features, labels, stats, centroids = cv2.connectedComponentsWithStats(imagem_segmentada)

# Lista para armazenar excentricidade de cada componente
excentricidades = []

for label in range(1, num_features):  # Ignorar o fundo (label 0)
    # Criar máscara para o label atual
    mask = (labels == label).astype(np.uint8)

    # Calcular momentos
    moments = cv2.moments(mask)

    # Calcular matriz de covariância
    if moments["m00"] > 0:  # Evitar divisão por zero
        x_central = moments["m10"] / moments["m00"]
        y_central = moments["m01"] / moments["m00"]

        # Segunda ordem centralizada
        mu20 = moments["mu20"] / moments["m00"]
        mu02 = moments["mu02"] / moments["m00"]
        mu11 = moments["mu11"] / moments["m00"]

        # Autovalores da matriz de covariância
        cov_matrix = np.array([[mu20, mu11], [mu11, mu02]])
        eigvals, _ = np.linalg.eig(cov_matrix)
        
        # Ordenar autovalores (lambda_1 >= lambda_2)
        eigvals = sorted(eigvals, reverse=True)

        # Calcular excentricidade
        if eigvals[1] > 0:  # Garantir autovalor positivo
            excentricidade = np.sqrt(1 - (eigvals[1] / eigvals[0]))
        else:
            excentricidade = 1  # Caso degenerado (linha ou ponto)

        excentricidades.append((label, excentricidade))

# Definir limiar para classificar como parafusos (ex: excentricidade > 0.8)
limiar_excentricidade = 0.8
parafusos = [label for label, excentricidade in excentricidades if excentricidade > limiar_excentricidade]

# Exibir resultados
print(f"Número total de componentes: {num_features - 1}")
print(f"Parafusos detectados (labels): {parafusos}")

# Visualizar a segmentação e destacar parafusos
output_image = np.zeros_like(image)
for label in parafusos:
    output_image[labels == label] = [255, 0, 0]  # Colorir parafusos em vermelho

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title("Imagem Original")
plt.imshow(image)
plt.axis("off")

plt.subplot(1, 2, 2)
plt.title("Parafusos Detectados")
plt.imshow(output_image)
plt.axis("off")
plt.show()

                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <br>
                Número total de componentes: 4
                <br>
                Parafusos detectados (labels): [1, 2]
                <br>


                <img src='./images/output_exe_4.png' style="width : 100%">
            </section>
        </section>

        <section id="Exercicio5">
            <h2>Exercício 5</h2>
            <section id="teoria">
                <article>
                    O código começa por carregar uma imagem chamada `aruco.png` usando `plt.imread()`. Em seguida, cria uma máscara binária, `I_seg`, que segmenta a imagem com base nos valores das cores (verificando se as componentes RGB de cada pixel são iguais a 1, o que indica um pixel branco). A segmentação resulta em uma imagem binária onde os pixels brancos são representados por 1 e os outros por 0.
<br>
O código calcula as dimensões da imagem (altura e largura) e define a altura e a largura das células (ou blocos) que serão analisadas, dividindo a altura e a largura da imagem em 8 partes (`step_y` e `step_x`). Em seguida, percorre a imagem em uma grade, começando de um ponto central dentro de cada bloco (usando um deslocamento de metade do tamanho do bloco) e coleta os valores binários (0 ou 1) para cada célula, armazenando-os na lista `codigo`.
<br>
A lista `codigo`, que contém os valores extraídos de cada célula, é então impressa no terminal e também exibida no título da imagem, para mostrar o código extraído da imagem.
<br>
Por fim, a imagem original é exibida com o título indicando o código extraído, onde os valores de `codigo` são apresentados sem vírgulas entre os elementos.
<br>
Este processo pode ser utilizado para extrair padrões binários de uma imagem, como um código binário presente em um marcador ArUco, por exemplo.
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
# -*- coding: utf-8 -*-
"""
Created on Mon Dec 16 12:35:25 2024

@author: JoaoMaria

Obrigado Gil :)
"""

import numpy as np
import matplotlib.pyplot as plt

I = plt.imread("aruco.png")

I_seg = ((I[...,0]==1)*(I[...,1]==1)*(I[...,2]==1)).astype(int)

height, width = I_seg.shape

step_y = height // 8
step_x = width // 8

codigo = []

for i in range(step_y + step_y//2, height-step_y, step_y):
    for j in range(step_x + step_x//2, width-step_x, step_x):
        codigo.append(I_seg[i,j])
        
print(codigo)
plt.imshow(I)
plt.title(f'Código extraido : \n {str(codigo).replace(',', '')}')
plt.show()
                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <img src='./images/output_exe_5.png' style="width : 100%">
            </section>
        </section>

        <section id="Exercicio6_1">
            <h2>Exercício 6.1</h2>
            <section id="teoria">
                <article>
                    Este código começa por carregar a imagem "monaLisa.png" usando `plt.imread()`. Em seguida, define manualmente quatro pontos da imagem original (`pontos_original`) que serão usados para calcular a transformação de perspectiva. A largura e a altura da nova imagem são calculadas com base nas distâncias entre os pontos 3 e 4 (para a largura) e entre os pontos 1 e 2 (para a altura). Após isso, os pontos de destino (`pontos_destino`) são definidos, representando o novo quadrilátero para o qual a imagem será transformada, mantendo as proporções da área selecionada.
<br>
A função `cv2.getPerspectiveTransform` é utilizada para calcular a matriz de transformação perspectiva (M) a partir dos pontos originais e de destino. Esta matriz é então aplicada à imagem original com a função `cv2.warpPerspective`, resultando em uma nova imagem que exibe apenas a região correspondente ao quadrilátero definido pelos pontos originais. A imagem original e a imagem transformada (cortada) são exibidas lado a lado usando `matplotlib`.
<br>
Este processo é útil para recortar e corrigir a perspectiva de uma área específica de uma imagem, como uma forma de "destransformar" uma parte de uma imagem para que ela fique em uma vista ortogonal.
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Carregar imagem
imagem_original = plt.imread('monaLisa.png')

# Converter para escala de cinza (como no seu exemplo)
#gray = 0.3 * imagem_original[..., 0] + 0.5 * imagem_original[..., 1] + 0.2 * imagem_original[..., 2]

# Definir os pontos da imagem original (manualmente)
pontos_original = np.float32([[722, 409], [874, 828], [1154, 760], [1000, 357]])

# Calcular a largura e altura com base nos pontos
largura = 500
altura = 800

# Ajustar os pontos de destino mantendo as proporções
pontos_destino = np.float32([[0, 0], [0, altura], [largura, altura], [largura, 0]])

# Obter a matriz de transformação perspectiva
M = cv2.getPerspectiveTransform(pontos_original, pontos_destino)

# Aplicar a transformação perspectiva
out = cv2.warpPerspective(imagem_original, M, (largura, altura), flags=cv2.INTER_LINEAR)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.title("Imagem Original")
plt.imshow(imagem_original)
plt.subplot(1, 2, 2)
plt.imshow(out)
plt.title("Imagem Cortada")

plt.show()

                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <img src='./images/output_exe_6_1.png' style="width : 100%">
            </section>
        </section>

        <section id="Exercicio6_2">
            <h2>Exercício 6.2</h2>
            <section id="teoria">
                <article>
                    O código carrega uma imagem, converte-a para o espaço de cores HSV e cria uma máscara binária, onde áreas específicas de cor são destacadas com base em critérios definidos para matiz, saturação e valor. Em seguida, aplica operações morfológicas (delação e erosão) para melhorar a qualidade da máscara, removendo ruídos e ajustando as áreas de interesse. Com a máscara refinada, o código encontra os contornos da região relevante na imagem, selecionando o contorno de maior área. Esse contorno é então aproximado para uma forma mais simples, como um quadrado ou retângulo, utilizando a técnica de aproximação poligonal. Após isso, é calculado o retângulo delimitador ao redor da forma e ajustada a posição dos cantos para corresponder aos pontos corretos da imagem original. Finalmente, uma transformação de perspectiva é aplicada à imagem para "endireitar" a região de interesse, gerando uma versão retangular da área selecionada, que é visualizada lado a lado com a imagem original.    
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
import cv2
import numpy as np
import matplotlib.pyplot as plt


def distance(point1, point2):
    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)


img = (plt.imread("monalisa.png") * 255).astype(np.uint8)
img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
img_bin = (
    (img_hsv[:, :, 0] > 16)
    & (img_hsv[:, :, 0] < 23)
    & (img_hsv[:, :, 1] > 87)
    & (img_hsv[:, :, 1] < 141)
    & (img_hsv[:, :, 2] > 220)
    & (img_hsv[:, :, 2] < 255)
)

kernel3 = np.ones((3, 3))
img_bin = cv2.dilate((img_bin * 255).astype(np.uint8), kernel=kernel3, iterations=3)
img_bin = cv2.erode(img_bin, kernel=kernel3, iterations=5)
img_bin = cv2.dilate(img_bin, kernel=kernel3, iterations=5)


contours, _ = cv2.findContours(img_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contour = sorted(contours, key=cv2.contourArea, reverse=True)[1]
epsilon = 0.05 * cv2.arcLength(contour, True)
approx = cv2.approxPolyDP(contour, epsilon, True)

approx = approx.reshape((4, 2))

x, y, w, h = cv2.boundingRect(approx)
bounding = [(x, y), (x + w, y), (x, y+h), (x + w, y + h)]
src_points = []
src_points_dst = [float("inf")]*4

for i, b in enumerate(bounding):
    for canto in approx:
        if (dst:=distance(b, canto)) < src_points_dst[i]:
            if len(src_points) != i:
                src_points[-1] = canto
            else:
                src_points.append(canto)
            src_points_dst[i] = dst

src_points = np.array(src_points, dtype="float32")
dst_points = np.array([[0, 0], [500, 0], [0, 800], [500, 800]], dtype="float32")
matriz_formacao = cv2.getPerspectiveTransform(src_points, dst_points)
transformed_img = cv2.warpPerspective(img, matriz_formacao, (500,800))


plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.title("Imagem Original")
plt.imshow(img)
plt.subplot(1, 2, 2)
plt.imshow(transformed_img)
plt.title("Imagem Cortada")
plt.show()

                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <img src='./images/output_exe_6_2.png' style="width : 100%">
            </section>
        </section>

        <section id="Exercicio6_3">
            <h2>Exercício 6.3</h2>
            <section id="teoria">
                <article>
                    O código começa por carregar uma imagem e convertê-la para o espaço de cores HSV para facilitar a segmentação de cores. Depois, ele cria uma máscara binária, onde áreas específicas da imagem que correspondem a certos critérios de cor são destacadas. Essa máscara passa por algumas operações de dilatação e erosão para melhorar a definição das regiões de interesse e eliminar ruídos. Em seguida, o código detecta os contornos na imagem e seleciona o maior contorno, que é então aproximado para um polígono com quatro lados. A partir dessa aproximação, o código calcula os limites da região e ajusta os pontos de destino para uma transformação de perspectiva. Essa transformação é aplicada à imagem original para "endireitar" a área de interesse, gerando uma versão retangular dessa região. Por fim, o código exibe a imagem original e a imagem transformada lado a lado.
                </article>
            </section>
            
            
            <div class="code-container">
                <!-- Alterado para textarea -->
                <textarea id="Exe1" class="codeBox">
import cv2
import numpy as np
import matplotlib.pyplot as plt


def distance(point1, point2):
    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)


img = (plt.imread("monalisa.png") * 255).astype(np.uint8)
img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
img_bin = (
    (img_hsv[:, :, 0] > 16)
    & (img_hsv[:, :, 0] < 23)
    & (img_hsv[:, :, 1] > 87)
    & (img_hsv[:, :, 1] < 141)
    & (img_hsv[:, :, 2] > 220)
    & (img_hsv[:, :, 2] < 255)
)

kernel3 = np.ones((3, 3))
img_bin = cv2.dilate((img_bin * 255).astype(np.uint8), kernel=kernel3, iterations=3)
img_bin = cv2.erode(img_bin, kernel=kernel3, iterations=5)
img_bin = cv2.dilate(img_bin, kernel=kernel3, iterations=5)


contours, _ = cv2.findContours(img_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contour = sorted(contours, key=cv2.contourArea, reverse=True)[1]
epsilon = 0.05 * cv2.arcLength(contour, True)
approx = cv2.approxPolyDP(contour, epsilon, True)

approx = approx.reshape((4, 2))

x, y, w, h = cv2.boundingRect(approx)
bounding = [(x, y), (x + w, y), (x, y+h), (x + w, y + h)]
src_points = []
src_points_dst = [float("inf")]*4

for i, b in enumerate(bounding):
    for canto in approx:
        if (dst:=distance(b, canto)) < src_points_dst[i]:
            if len(src_points) != i:
                src_points[-1] = canto
            else:
                src_points.append(canto)
            src_points_dst[i] = dst

src_points = np.array(src_points, dtype="float32")

# Calcular a largura e altura com base nos pontos
largura = int(np.linalg.norm(src_points[2] - src_points[3]))  # Distância entre ponto 3 e 4
altura = int(np.linalg.norm(src_points[1] - src_points[0]))   # Distância entre ponto 2 e 1

# Ajustar os pontos de destino mantendo as proporções
pontos_destino = np.float32([[0, 0],[largura, 0],[0, altura] , [largura, altura]])

matriz_formacao = cv2.getPerspectiveTransform(src_points, pontos_destino)
transformed_img = cv2.warpPerspective(img, matriz_formacao, (largura,altura))


plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.title("Imagem Original")
plt.imshow(img)
plt.subplot(1, 2, 2)
plt.imshow(transformed_img)
plt.title("Imagem Cortada")
plt.show()


                </textarea>
                <button class="copyButton">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar Código</span>
                </button>                
            </div>
            <section id="teoria">
                Output:
                <img src='./images/output_exe_6_3.png' style="width : 100%">
            </section>
        </section>

    </main>

    <script src="script.js"></script>
</body>
</html>
    